import torch
import torch.nn as nn
import matplotlib.pyplot as plt

from torch.autograd import Variable
from torch.onnx.symbolic_opset9 import tensor

# Custom DataSet
import iris


class IrisNet(nn.Module):

    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):
        super(IrisNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden1_size)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden1_size, hidden2_size)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden2_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu1(out)
        out = self.fc2(out)
        out = self.relu2(out)
        out = self.fc3(out)
        return out

model = IrisNet(4, 100, 50, 3)
print(model)

batch_size = 60
iris_data_file = '.\..\..\Data\iris.data.txt'

# Get the datasets
train_ds, test_ds = iris.get_datasets(iris_data_file)

# How many instances have we got?
print('# instances in training set: ', len(train_ds))
print('# instances in testing/validation set: ', len(test_ds))

# Create the dataloaders - for training and validation/testing
# We will be using the term validation and testing data interchangably
train_loader = torch.utils.data.DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)
test_loader  = torch.utils.data.DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=True)

# Instantiate the network, the loss function and the optimizer
# Our model
net = IrisNet(4, 100, 50, 3)

# Out loss function
criterion = nn.CrossEntropyLoss()

# Our optimizer
learning_rate = 0.001
optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, nesterov=True, momentum=0.9, dampening=0)

#Train it!
num_epochs = 500

train_loss = []
test_loss = []
train_accuracy = []
test_accuracy = []

for epoch in range(num_epochs):

    train_correct = 0
    train_total = 0

    for i, (items, classes) in enumerate(train_loader):
        # Convert torch tensor to Variable
        items = Variable(items)
        classes = Variable(classes)

        net.train()  # Put the network into training mode

        optimizer.zero_grad()  # Clear off the gradients from any past operation
        outputs = net(items)  # Do the forward pass
        loss = criterion(outputs, classes)  # Calculate the loss
        loss.backward()  # Calculate the gradients with help of back propagation
        optimizer.step()  # Ask the optimizer to adjust the parameters based on the gradients

        # Record the correct predictions for training data
        train_total += classes.size(0)
        _, predicted = torch.max(outputs.data, 1)
        train_correct += (predicted == classes.data).sum()

        print('Epoch %d/%d, Iteration %d/%d, Loss: %.4f'
              % (epoch + 1, num_epochs, i + 1, len(train_ds) // batch_size, loss.data))

    net.eval()  # Put the network into evaluation mode

    # Bookkeeping
    # Record the loss
    train_loss.append(loss.data)

    # What was our train accuracy?
    train_accuracy.append((100 * train_correct / train_total))

    # How did we do on the test set (the unseen set)
    # Record the correct predictions for test data
    test_items = torch.FloatTensor(test_ds.data.values[:, 0:4])
    test_classes = torch.LongTensor(test_ds.data.values[:, 4])

    outputs = net(Variable(test_items))
    loss = criterion(outputs, Variable(test_classes))
    test_loss.append(loss.data)
    _, predicted = torch.max(outputs.data, 1)
    total = test_classes.size(0)
    correct = (predicted == test_classes).sum()
    test_accuracy.append((100 * correct / total))

#Plot loss vs iterations
fig = plt.figure(figsize=(12, 8))
plt.plot(train_loss, label='train loss')
plt.plot(test_loss, label='test loss')
plt.title("Train and Test Loss")
plt.legend()
plt.show()

fig = plt.figure(figsize=(12, 8))
plt.plot(train_accuracy, label='train accuracy')
plt.plot(test_accuracy, label='test accuracy')
plt.title("Train and Test Accuracy")
plt.legend()
plt.show()

#Savign the model to disk, and loading it back
torch.save(net.state_dict(), "./data/2.model.pth")
net2 = IrisNet(4, 100, 50, 3)
net2.load_state_dict(torch.load("./data/2.model.pth"))
output = net2(Variable(torch.FloatTensor([[5.1, 3.5, 1.4, 0.2]])))
_, predicted_class = torch.max(output.data, 1)
print('Predicted class: ', predicted_class.numpy()[0])
print('Expected class: ', 0 )